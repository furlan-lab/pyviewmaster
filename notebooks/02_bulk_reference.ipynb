{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "micromamba activate scvelo_jupyter_new\n",
    "micromamba run -n scvelo_jupyter_new pip install rds2py\n",
    "micromamba run -n scvelo_jupyter_new pip install twine\n",
    "micromamba run -n scvelo_jupyter_new pip install git+https://github.com/furlan-lab/pyviewmaster.git\n",
    "micromamba run -n scvelo_jupyter_new pip install plotly==5.24.1\n",
    "micromamba run -n scvelo_jupyter_new pip install colorcet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scverse libraries\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import scvelo as scv\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sc.settings.set_figure_params(dpi=100, facecolor=\"white\")\n",
    "import socket\n",
    "from pyviewmaster import *\n",
    "import seaborn as sns\n",
    "import colorcet as cc\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "if hostname.startswith(\"gizmo\"):\n",
    "  ROOT_DIR1 = \"/fh/fast/furlan_s/datasets/AML/LOR_classifier/cds\"\n",
    "  ROOT_DIR2 = \"/fh/fast/furlan_s/grp/data/ddata/BM_data\"\n",
    "else:\n",
    "  ROOT_DIR1 = \"/Users/sfurlan/Library/CloudStorage/OneDrive-SharedLibraries-FredHutchinsonCancerCenter/Furlan_Lab - General/datasets/AML/LOR_classifier/cds\"\n",
    "  ROOT_DIR2 = \"/Users/sfurlan/Library/CloudStorage/OneDrive-SharedLibraries-FredHutchinsonCancerCenter/Furlan_Lab - General/experiments/patient_marrows/WC1/cds\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD SUMMARIZED EXPERIMENT OBJECT IN PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rds2py import read_rds\n",
    "ref =read_rds(ROOT_DIR1+\"/240126_Combined_SE_Object.RDS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coldata \u001b[38;5;241m=\u001b[39m \u001b[43mget_coldata_rds_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m coldata\u001b[38;5;241m.\u001b[39mset_index \u001b[38;5;241m=\u001b[39m coldata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrownames\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m rowdata \u001b[38;5;241m=\u001b[39m get_rowdata_rds_obj(ref)\n",
      "File \u001b[0;32m~/micromamba/envs/scvelo_jupyter_new/lib/python3.9/site-packages/pyviewmaster/utils.py:296\u001b[0m, in \u001b[0;36mget_coldata_rds_obj\u001b[0;34m(robj)\u001b[0m\n\u001b[1;32m    294\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    295\u001b[0m robject \u001b[38;5;241m=\u001b[39m robj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolData\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 296\u001b[0m col_names \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobject\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattributes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlistData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattributes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, colname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(col_names):\n\u001b[1;32m    298\u001b[0m     data[colname] \u001b[38;5;241m=\u001b[39m _dispatcher(robject[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistData\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx])\n",
      "File \u001b[0;32m~/micromamba/envs/scvelo_jupyter_new/lib/python3.9/site-packages/pyviewmaster/utils.py:258\u001b[0m, in \u001b[0;36m_dispatcher\u001b[0;34m(robject, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dispatcher\u001b[39m(robject: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 258\u001b[0m     _class_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_class\u001b[49m(robject)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_class' is not defined"
     ]
    }
   ],
   "source": [
    "coldata = get_coldata_rds_obj(ref)\n",
    "coldata.set_index = coldata[\"rownames\"]\n",
    "rowdata = get_rowdata_rds_obj(ref)\n",
    "rowdata.set_index = rowdata[\"gene_short_name\"]\n",
    "scounts = get_counts_rds_obj(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = ad.AnnData(scounts)\n",
    "rdata.obs = coldata\n",
    "rdata.var = rowdata\n",
    "rdata.obs_names = coldata.index\n",
    "rdata.var_names = rowdata.index\n",
    "rdata.layers[\"counts\"] = rdata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(rdata)\n",
    "sc.pp.log1p(rdata)\n",
    "sc.pp.highly_variable_genes(rdata, n_top_genes=10000)\n",
    "sc.pl.highly_variable_genes(rdata)\n",
    "sc.tl.pca(rdata, n_comps=200)\n",
    "sc.pl.pca_variance_ratio(rdata, n_pcs=200, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(rdata, n_pcs=200)\n",
    "\n",
    "sc.tl.umap(rdata, min_dist=0.4, n_components=3)\n",
    "\n",
    "sc.pl.umap(rdata, color = \"category1\", projection = \"3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(cc.glasbey, n_colors=50, as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdata.obsm['X_umap']\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = [\"umap1\", \"umap2\", \"umap3\"]\n",
    "df[\"category1\"] = rdata.obs[\"category1\"].values\n",
    "df.index = rdata.obs.index\n",
    "fig = px.scatter_3d(df, x='umap1', y='umap2', z='umap3',\n",
    "              color='category1', color_discrete_sequence = palette)\n",
    "fig.update_traces(marker_size = 1.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_loom(ROOT_DIR2+\"/WC_velocity.loom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color = \"celltype\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = adata\n",
    "ref = rdata\n",
    "N=6\n",
    "bulk_feature_row=\"gene_short_name\"\n",
    "bulk_assay_name=\"counts\"\n",
    "sc_assay_name=\"matrix\"\n",
    "dist=\"sc-direct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume counts_query and sizes are already defined from earlier code\n",
    "counts_query = get_counts_adata(query, layer=sc_assay_name)\n",
    "sizes = sum_counts(counts_query, axis=1)\n",
    "min_size = sizes.min()\n",
    "max_size = sizes.max()\n",
    "\n",
    "# Number of single cells to generate\n",
    "ss_cells = N * ref.shape[0]\n",
    "\n",
    "if dist == \"sc-model\":\n",
    "    print(\"Modeling count distribution of query using Empirical CDF\")\n",
    "    # Sort sizes to create the CDF\n",
    "    sorted_sizes = np.sort(sizes)\n",
    "    cdf = np.arange(1, len(sorted_sizes) + 1) / len(sorted_sizes)\n",
    "    # Draw random samples from a uniform distribution\n",
    "    uniform_samples = np.random.rand(ss_cells)\n",
    "    # Use inverse transform sampling to get values that match the empirical CDF\n",
    "    final_newsizes = np.interp(uniform_samples, cdf, sorted_sizes).astype(int)\n",
    "\n",
    "else:\n",
    "    # Use the direct sampling approach for \"sc-direct\" as before\n",
    "    final_newsizes = np.random.choice(sizes, ss_cells, replace=True).astype(int)\n",
    "\n",
    "print(\"Finding common features between ref and query\")\n",
    "genes_query = query.var_names\n",
    "genes_ref = ref.var[bulk_feature_row].values\n",
    "universe = np.intersect1d(genes_ref, genes_query)\n",
    "\n",
    "if len(universe) == 0:\n",
    "    raise ValueError(\"No common genes found between ref and query.\")\n",
    "\n",
    "print(f\"Simulating {N} single cells for every bulk dataset case\")\n",
    "\n",
    "# Prepare the reference counts data\n",
    "counts_ref_full = get_counts_adata(ref, layer=\"counts\")\n",
    "counts_ref_full = pd.DataFrame(counts_ref_full.todense().T)\n",
    "counts_ref_full.index = genes_ref\n",
    "counts_ref_full.columns = counts_ref_full.columns.astype(str)\n",
    "counts_ref_full = counts_ref_full.loc[universe, :]\n",
    "fdata = anndata.AnnData(counts_ref_full.T)\n",
    "fdata.obs = ref.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.kdeplot(final_newsizes)\n",
    "sns.histplot(final_newsizes, bins = 100)\n",
    "print(len(final_newsizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.kdeplot(sizes)\n",
    "sns.histplot(sizes, bins = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "def downsample_counts_vectorized(counts_matrix, new_total_counts):\n",
    "    \"\"\"\n",
    "    Downsamples counts for multiple cells using vectorized multinomial sampling.\n",
    "    \n",
    "    Parameters:\n",
    "    counts_matrix (np.array): 2D array of counts (cells x genes).\n",
    "    new_total_counts (np.array): 1D array of target total counts for downsampling (length = number of cells).\n",
    "    \n",
    "    Returns:\n",
    "    np.array: Downsampled counts matrix.\n",
    "    \"\"\"\n",
    "    # Compute total counts per cell\n",
    "    original_total_counts = counts_matrix.sum(axis=1)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    nonzero_mask = original_total_counts > 0\n",
    "    \n",
    "    # Compute probabilities\n",
    "    probabilities = np.zeros_like(counts_matrix, dtype=float)\n",
    "    probabilities[nonzero_mask] = counts_matrix[nonzero_mask] / original_total_counts[nonzero_mask, np.newaxis]\n",
    "    \n",
    "    # Initialize the random number generator\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    # Prepare an array to hold the downsampled counts\n",
    "    downsampled_counts = np.zeros_like(counts_matrix, dtype=int)\n",
    "    \n",
    "    # Perform multinomial sampling where both original and new total counts are greater than zero\n",
    "    valid_mask = nonzero_mask & (new_total_counts > 0)\n",
    "    if np.any(valid_mask):\n",
    "        downsampled_counts[valid_mask] = rng.multinomial(\n",
    "            n=new_total_counts[valid_mask],\n",
    "            pvals=probabilities[valid_mask]\n",
    "        )\n",
    "    \n",
    "    return downsampled_counts\n",
    "\n",
    "def expand_anndata(adata, fold=10, total_counts_vector=None):\n",
    "    \"\"\"\n",
    "    Expands an AnnData object to `fold` times its size by downsampling the counts\n",
    "    using random sampling and total counts provided by the user. The `obs` DataFrame\n",
    "    is similarly expanded.\n",
    "    \n",
    "    Parameters:\n",
    "    adata (AnnData): The input AnnData object.\n",
    "    fold (int): The factor by which to expand the data.\n",
    "    total_counts_vector (np.array): 1D array of total counts for downsampled cells.\n",
    "                                    Its length should be equal to `adata.n_obs * fold`.\n",
    "    \n",
    "    Returns:\n",
    "    AnnData: A new AnnData object with the expanded data and expanded `obs`.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import issparse\n",
    "\n",
    "    # Convert original counts to a dense matrix if sparse\n",
    "    if issparse(adata.X):\n",
    "        original_counts = adata.X.toarray()\n",
    "    else:\n",
    "        original_counts = adata.X.copy()\n",
    "    \n",
    "    # Get the number of original cells and genes\n",
    "    num_cells, num_genes = original_counts.shape\n",
    "    \n",
    "    # Validate the total_counts_vector\n",
    "    if total_counts_vector is not None:\n",
    "        expected_length = num_cells * fold\n",
    "        if len(total_counts_vector) != expected_length:\n",
    "            raise ValueError(\n",
    "                f\"The length of total_counts_vector ({len(total_counts_vector)}) \"\n",
    "                f\"must be equal to the number of expanded cells ({expected_length}).\"\n",
    "            )\n",
    "        # Ensure non-negative integer counts\n",
    "        new_total_counts = np.maximum(np.array(total_counts_vector, dtype=int), 0)\n",
    "    else:\n",
    "        # Use the original total counts repeated `fold` times\n",
    "        original_total_counts = original_counts.sum(axis=1)\n",
    "        new_total_counts = np.tile(original_total_counts, fold)\n",
    "    \n",
    "    # Expand counts by repeating each cell `fold` times\n",
    "    expanded_counts = np.repeat(original_counts, fold, axis=0)\n",
    "    \n",
    "    # Downsample counts using vectorized multinomial sampling\n",
    "    downsampled_counts = downsample_counts_vectorized(expanded_counts, new_total_counts)\n",
    "    \n",
    "    # Expand the obs DataFrame\n",
    "    expanded_obs = pd.DataFrame(\n",
    "        np.repeat(adata.obs.values, fold, axis=0),\n",
    "        columns=adata.obs.columns\n",
    "    )\n",
    "    \n",
    "    # Generate replicate numbers and new observation names\n",
    "    replicate_numbers = np.tile(np.arange(1, fold + 1), num_cells)\n",
    "    repeated_indices = np.repeat(adata.obs_names.values, fold)\n",
    "    expanded_obs_names = [\n",
    "        f\"{obs}_rep{rep}\" for obs, rep in zip(repeated_indices, replicate_numbers)\n",
    "    ]\n",
    "    expanded_obs.index = expanded_obs_names\n",
    "    \n",
    "    # Create a new AnnData object with the downsampled counts and expanded obs\n",
    "    expanded_adata = ad.AnnData(\n",
    "        X=sparse.csr_matrix(downsampled_counts),\n",
    "        obs=expanded_obs,\n",
    "        var=adata.var.copy()\n",
    "    )\n",
    "    \n",
    "    return expanded_adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdataf = expand_anndata(fdata, fold= 6, total_counts_vector=final_newsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(fdataf)\n",
    "sc.pp.log1p(fdataf)\n",
    "sc.pp.highly_variable_genes(fdataf, n_top_genes=10000)\n",
    "sc.pl.highly_variable_genes(fdataf)\n",
    "sc.tl.pca(fdataf, n_comps=50)\n",
    "sc.pl.pca_variance_ratio(fdataf, n_pcs=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(fdataf, n_pcs=50)\n",
    "\n",
    "sc.tl.umap(fdataf, min_dist=0.4, n_components=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc.pl.umap(fdataf, color = \"category1\", projection = \"3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fdataf.obsm['X_umap']\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = [\"umap1\", \"umap2\", \"umap3\"]\n",
    "df[\"category1\"] = fdataf.obs[\"category1\"].values\n",
    "df.index = fdataf.obs.index\n",
    "fig = px.scatter_3d(df, x='umap1', y='umap2', z='umap3',\n",
    "              color='category1', color_discrete_sequence = palette)\n",
    "fig.update_traces(marker_size = 1.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(query, color = \"celltype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewmaster(query_cds=query, ref_cds=fdataf, ref_celldata_col=\"category1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(query, color = \"viewmaster_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(query, color = \"viewmaster_pred\", groups = \"KMT2A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = query.obsm['X_umap']\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = [\"umap1\", \"umap2\"]\n",
    "df[\"category1\"] = query.obs[\"viewmaster_pred\"].values\n",
    "df.index = query.obs.index\n",
    "fig = px.scatter(df, x='umap1', y='umap2',\n",
    "              color='category1', color_discrete_sequence = palette)\n",
    "fig.update_traces(marker_size = 1.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sum_counts(fdataf.X, axis=1), bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy import sparse\n",
    "\n",
    "def simulate_single_cells(\n",
    "    ref,\n",
    "    query,\n",
    "    N,\n",
    "    dist='sc-direct',\n",
    "    sc_assay_name='counts',\n",
    "    bulk_assay_name='counts',\n",
    "    bulk_feature_row='gene_short_name'\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates N single cells for every bulk dataset case in `ref`,\n",
    "    using the count distribution from `query`.\n",
    "    \n",
    "    Parameters:\n",
    "    - ref (AnnData): The bulk reference AnnData object.\n",
    "    - query (AnnData): The single-cell query AnnData object.\n",
    "    - N (int): Number of single cells to generate per sample in `ref`.\n",
    "    - dist (str): Distribution to use for generating total counts ('sc-model' or 'sc-direct').\n",
    "    - sc_assay_name (str): Name of the layer in `query` containing scRNA-seq counts.\n",
    "    - bulk_feature_row (str): Column name in `ref.var` containing gene identifiers.\n",
    "    \n",
    "    Returns:\n",
    "    - expanded_adata (AnnData): An AnnData object with simulated single-cell data.\n",
    "    \"\"\"\n",
    "    def get_counts_adata(adata, layer=None):\n",
    "        \"\"\"\n",
    "        Retrieves the counts matrix from an AnnData object.\n",
    "        If layer is specified, uses that layer; otherwise, uses adata.X.\n",
    "        \"\"\"\n",
    "        if layer is not None:\n",
    "            counts = adata.layers[layer]\n",
    "        else:\n",
    "            counts = adata.X\n",
    "        return counts\n",
    "\n",
    "    # Get counts from the query dataset\n",
    "    counts_query = get_counts_adata(query, layer=sc_assay_name)\n",
    "    if sparse.issparse(counts_query):\n",
    "        sizes = counts_query.sum(axis=1).A1  # Convert to 1D array\n",
    "    else:\n",
    "        sizes = counts_query.sum(axis=1)\n",
    "    # min_size = sizes.min()\n",
    "    # max_size = sizes.max()\n",
    "    \n",
    "    # Number of single cells to generate\n",
    "    ss_cells = N * ref.shape[0]\n",
    "    \n",
    "    # Generate total counts for downsampled cells\n",
    "    if dist == \"sc-model\":\n",
    "        print(\"Modeling count distribution of query using Empirical CDF\")\n",
    "        # Sort sizes to create the CDF\n",
    "        sorted_sizes = np.sort(sizes)\n",
    "        cdf = np.arange(1, len(sorted_sizes) + 1) / len(sorted_sizes)\n",
    "        # Draw random samples from a uniform distribution\n",
    "        uniform_samples = np.random.rand(ss_cells)\n",
    "        # Use inverse transform sampling to get values that match the empirical CDF\n",
    "        final_newsizes = np.interp(uniform_samples, cdf, sorted_sizes).astype(int)\n",
    "    else:\n",
    "        # Use the direct sampling approach for \"sc-direct\"\n",
    "        final_newsizes = np.random.choice(sizes, ss_cells, replace=True).astype(int)\n",
    "    \n",
    "    print(\"Finding common features between ref and query\")\n",
    "    genes_query = query.var_names\n",
    "    genes_ref = ref.var[bulk_feature_row].values\n",
    "    universe = np.intersect1d(genes_ref, genes_query)\n",
    "    \n",
    "    if len(universe) == 0:\n",
    "        raise ValueError(\"No common genes found between ref and query.\")\n",
    "    \n",
    "    print(f\"Simulating {N} single cells for every bulk dataset case\")\n",
    "    \n",
    "    # Prepare the reference counts data\n",
    "    counts_ref_full = get_counts_adata(ref, layer=bulk_assay_name)\n",
    "    if sparse.issparse(counts_ref_full):\n",
    "        counts_ref_full = counts_ref_full.todense()\n",
    "    counts_ref_full = pd.DataFrame(\n",
    "        counts_ref_full.T,\n",
    "        index=ref.var_names,\n",
    "        columns=ref.obs_names\n",
    "    )\n",
    "    # Ensure genes_ref are aligned with counts_ref_full\n",
    "    counts_ref_full = counts_ref_full.loc[genes_ref]\n",
    "    # Keep only the common genes\n",
    "    counts_ref_full = counts_ref_full.loc[universe]\n",
    "    # Create an AnnData object with the filtered counts\n",
    "    fdata = ad.AnnData(counts_ref_full.T)\n",
    "    fdata.obs = ref.obs.copy()\n",
    "    \n",
    "    # Ensure the number of cells matches\n",
    "    assert ss_cells == fdata.n_obs * N, \"Mismatch in the number of single cells to generate.\"\n",
    "    \n",
    "    # Define the downsampling function\n",
    "    def downsample_counts_vectorized(counts_matrix, new_total_counts):\n",
    "        \"\"\"\n",
    "        Downsamples counts for multiple cells using vectorized multinomial sampling.\n",
    "        \"\"\"\n",
    "        # Compute total counts per cell\n",
    "        original_total_counts = counts_matrix.sum(axis=1)\n",
    "        # Avoid division by zero\n",
    "        nonzero_mask = original_total_counts > 0\n",
    "        # Compute probabilities\n",
    "        probabilities = np.zeros_like(counts_matrix, dtype=float)\n",
    "        probabilities[nonzero_mask] = (\n",
    "            counts_matrix[nonzero_mask] /\n",
    "            original_total_counts[nonzero_mask, np.newaxis]\n",
    "        )\n",
    "        # Initialize the random number generator\n",
    "        rng = np.random.default_rng()\n",
    "        # Prepare an array to hold the downsampled counts\n",
    "        downsampled_counts = np.zeros_like(counts_matrix, dtype=int)\n",
    "        # Perform multinomial sampling where valid\n",
    "        valid_mask = nonzero_mask & (new_total_counts > 0)\n",
    "        if np.any(valid_mask):\n",
    "            downsampled_counts[valid_mask] = rng.multinomial(\n",
    "                n=new_total_counts[valid_mask],\n",
    "                pvals=probabilities[valid_mask]\n",
    "            )\n",
    "        return downsampled_counts\n",
    "\n",
    "    # Define the expand function\n",
    "    def expand_anndata(adata, fold=10, total_counts_vector=None):\n",
    "        \"\"\"\n",
    "        Expands an AnnData object by downsampling counts using vectorized sampling.\n",
    "        The `obs` DataFrame is similarly expanded.\n",
    "        \"\"\"\n",
    "        # Convert counts to dense matrix if sparse\n",
    "        if sparse.issparse(adata.X):\n",
    "            original_counts = adata.X.toarray()\n",
    "        else:\n",
    "            original_counts = adata.X.copy()\n",
    "        \n",
    "        num_cells, num_genes = original_counts.shape\n",
    "        \n",
    "        # Validate the total_counts_vector\n",
    "        if total_counts_vector is not None:\n",
    "            expected_length = num_cells * fold\n",
    "            if len(total_counts_vector) != expected_length:\n",
    "                raise ValueError(\n",
    "                    f\"The length of total_counts_vector ({len(total_counts_vector)}) \"\n",
    "                    f\"must be equal to the number of expanded cells ({expected_length}).\"\n",
    "                )\n",
    "            new_total_counts = np.maximum(np.array(total_counts_vector, dtype=int), 0)\n",
    "        else:\n",
    "            # Use the original total counts repeated `fold` times\n",
    "            original_total_counts = original_counts.sum(axis=1)\n",
    "            new_total_counts = np.tile(original_total_counts, fold)\n",
    "        \n",
    "        # Expand counts by repeating each cell `fold` times\n",
    "        expanded_counts = np.repeat(original_counts, fold, axis=0)\n",
    "        \n",
    "        # Downsample counts using vectorized multinomial sampling\n",
    "        downsampled_counts = downsample_counts_vectorized(expanded_counts, new_total_counts)\n",
    "        \n",
    "        # Expand the obs DataFrame\n",
    "        expanded_obs = pd.DataFrame(\n",
    "            np.repeat(adata.obs.values, fold, axis=0),\n",
    "            columns=adata.obs.columns\n",
    "        )\n",
    "        \n",
    "        # Generate replicate numbers and new observation names\n",
    "        replicate_numbers = np.tile(np.arange(1, fold + 1), num_cells)\n",
    "        repeated_indices = np.repeat(adata.obs_names.values, fold)\n",
    "        expanded_obs_names = [\n",
    "            f\"{obs}_rep{rep}\" for obs, rep in zip(repeated_indices, replicate_numbers)\n",
    "        ]\n",
    "        expanded_obs.index = expanded_obs_names\n",
    "        \n",
    "        # Create a new AnnData object with the downsampled counts and expanded obs\n",
    "        expanded_adata = ad.AnnData(\n",
    "            X=sparse.csr_matrix(downsampled_counts),\n",
    "            obs=expanded_obs,\n",
    "            var=adata.var.copy()\n",
    "        )\n",
    "        \n",
    "        return expanded_adata\n",
    "    \n",
    "    # Expand the data\n",
    "    expanded_adata = expand_anndata(\n",
    "        fdata,\n",
    "        fold=N,\n",
    "        total_counts_vector=final_newsizes\n",
    "    )\n",
    "    \n",
    "    return expanded_adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = simulate_single_cells(rdata, adata, 6, \"sc-direct\", sc_assay_name=\"matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(fdata)\n",
    "sc.pp.log1p(fdata)\n",
    "sc.pp.highly_variable_genes(fdata, n_top_genes=10000)\n",
    "sc.pl.highly_variable_genes(fdata)\n",
    "sc.tl.pca(fdata, n_comps=50)\n",
    "sc.pl.pca_variance_ratio(fdata, n_pcs=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(fdataf, n_pcs=50)\n",
    "sc.tl.umap(fdataf, min_dist=0.4, n_components=3)\n",
    "sc.pl.umap(fdataf, color = \"category1\", projection = \"3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewmaster(query_cds=adata, ref_cds=fdata, ref_celldata_col=\"category1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(query, color = \"viewmaster_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(query, color = \"viewmaster_pred\", groups = \"Ph-like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvelo_jupyter_new",
   "language": "python",
   "name": "scvelo_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
